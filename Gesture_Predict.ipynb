{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('Gesture_Recognizing.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(cur):\n",
    "    fin_img = cv2.resize(cur, (100,100) )\n",
    "    fin_img = np.array(fin_img)\n",
    "    fin_img = fin_img.reshape( (1,100,100,1) )\n",
    "    fin_img = fin_img/255.0\n",
    "    result = model.predict( fin_img )\n",
    "    num = np.argmax( result[0] )\n",
    "    return num, result[0][num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "d\n",
      "4\n",
      "dd\n",
      "4\n",
      "ddd\n",
      "4\n",
      "dddd\n",
      "4\n",
      "ddddd\n",
      "4\n",
      "dddddd\n",
      "3\n",
      "ddddddc\n",
      "3\n",
      "ddddddcc\n",
      "3\n",
      "ddddddccc\n",
      "1\n",
      "ddddddccca\n",
      "2\n",
      "ddddddcccab\n",
      "3\n",
      "ddddddcccabc\n",
      "1\n",
      "ddddddcccabca\n",
      "1\n",
      "ddddddcccabcaa\n",
      "1\n",
      "ddddddcccabcaaa\n",
      "4\n",
      "ddddddcccabcaaad\n",
      "4\n",
      "ddddddcccabcaaadd\n",
      "4\n",
      "ddddddcccabcaaaddd\n",
      "5\n",
      "ddddddcccabcaaaddde\n",
      "5\n",
      "ddddddcccabcaaadddee\n",
      "5\n",
      "ddddddcccabcaaadddeee\n",
      "5\n",
      "ddddddcccabcaaadddeeee\n",
      "5\n",
      "ddddddcccabcaaadddeeeee\n",
      "5\n",
      "ddddddcccabcaaadddeeeeee\n",
      "6\n",
      "ddddddcccabcaaadddeeeeeef\n",
      "1\n",
      "a\n",
      "2\n",
      "ab\n",
      "6\n",
      "abf\n",
      "3\n",
      "abfc\n",
      "1\n",
      "abfca\n",
      "6\n",
      "abfcaf\n",
      "1\n",
      "abfcafa\n",
      "6\n",
      "abfcafaf\n",
      "5\n",
      "abfcafafe\n",
      "2\n",
      "abfcafafeb\n",
      "6\n",
      "abfcafafebf\n",
      "3\n",
      "abfcafafebfc\n",
      "1\n",
      "abfcafafebfca\n",
      "6\n",
      "abfcafafebfcaf\n",
      "5\n",
      "abfcafafebfcafe\n",
      "4\n",
      "abfcafafebfcafed\n",
      "5\n",
      "abfcafafebfcafede\n",
      "5\n",
      "abfcafafebfcafedee\n",
      "5\n",
      "abfcafafebfcafedeee\n",
      "5\n",
      "abfcafafebfcafedeeee\n",
      "5\n",
      "abfcafafebfcafedeeeee\n",
      "2\n",
      "abfcafafebfcafedeeeeeb\n",
      "2\n",
      "abfcafafebfcafedeeeeebb\n",
      "2\n",
      "abfcafafebfcafedeeeeebbb\n",
      "2\n",
      "abfcafafebfcafedeeeeebbbb\n",
      "2\n",
      "abfcafafebfcafedeeeeebbbbb\n",
      "2\n",
      "abfcafafebfcafedeeeeebbbbbb\n",
      "6\n",
      "abfcafafebfcafedeeeeebbbbbbf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.namedWindow(\"frame\", cv2.WINDOW_NORMAL)\n",
    "cv2.namedWindow(\"hand\", cv2.WINDOW_NORMAL)\n",
    "cap = cv2.VideoCapture(0)\n",
    "predicting = False\n",
    "cur_text = ''\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    img = cv2.rectangle(frame,(800,100),(1200,500),(0,255,255),3)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(img,'Align hand in this square',(800,80), font, 1,(0,0,0),2,cv2.LINE_AA)\n",
    "    cv2.putText(frame,cur_text,(800,530), font, 1,(0,0,0),2,cv2.LINE_AA)\n",
    "    cv2.imshow('frame',img)\n",
    "    x = 800\n",
    "    y = 100\n",
    "    side = 400\n",
    "    img_save = img[y:y+side, x:x+side]\n",
    "    img_save = cv2.cvtColor(img_save, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(img_save,(5,5),0)\n",
    "    ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    cv2.imshow(\"hand\", th3)\n",
    "    if predicting:\n",
    "        num, _ = predict(th3)\n",
    "        print num\n",
    "        if num!=0:\n",
    "            alph = chr(num+96)\n",
    "            cur_text += alph\n",
    "            print cur_text\n",
    "        predicting = False\n",
    "    keypress = cv2.waitKey(1)\n",
    "    \n",
    "    if keypress == ord('q'):\n",
    "        break\n",
    "    if keypress == ord('s'):\n",
    "        predicting = True\n",
    "    if keypress == ord('c'):\n",
    "        cur_text = ''\n",
    "    \n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
